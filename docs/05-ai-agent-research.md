# 🤖 AI × スマートコントラクトセキュリティ 総合調査

> AIエージェントによるバグバウンティ自動化に関する網羅的リサーチ

---

## 📊 調査概要

本調査では、以下の観点から網羅的に情報を収集した：

1. **学術研究** - LLM × スマートコントラクト脆弱性検出の論文
2. **既存ツール・プロジェクト** - AI監査ツールの現状
3. **エージェントフレームワーク** - LangGraph, CrewAI, AutoGPT比較
4. **技術的課題と限界** - 現状の課題と解決策
5. **プロジェクトへの示唆** - 本プロジェクトへの応用

---

## 📚 学術研究：LLM × スマートコントラクト

### 主要論文

#### 1. "Do you still need a manual smart contract audit?" (2023)
- **著者**: Isaac David, Liyi Zhou, Kaihua Qin, Dawn Song, et al.
- **URL**: [arXiv:2306.12338](https://arxiv.org/abs/2306.12338)
- **主な発見**:
  - GPT-4とClaudeで脆弱性タイプを **40%** 正しく特定
  - しかし **高い偽陽性率** が問題
  - LLMはランダムモデルより **F1スコアで20%** 優れる
  - 最良ケースで **78.7%の真陽性率** (GPT-4-32k)
- **示唆**: LLM単体では不十分、人間の監査者との併用が必要

#### 2. "When ChatGPT Meets Smart Contract Vulnerability Detection" (2023/2024)
- **著者**: Chong Chen et al.
- **URL**: [arXiv:2309.05520](https://arxiv.org/abs/2309.05520)
- **掲載**: ACM TOSEM 2025
- **主な発見**:
  - ChatGPTは **高いRecall** だが **低いPrecision**
  - 脆弱性タイプによって性能が大きく異なる
  - 偽陽性の原因を4カテゴリに分類
  - 7種の脆弱性中3種で既存ツールより劣る
  - **ロバスト性の改善が必要**（回答の不確実性、コード長制限）

#### 3. "GPTLens: LLM-Powered Smart Contract Vulnerability Detection" (2023)
- **著者**: Sihao Hu, Tiansheng Huang, et al.
- **URL**: [arXiv:2310.01152](https://arxiv.org/abs/2310.01152)
- **掲載**: IEEE TPS 2023
- **コード**: [github.com/git-disl/GPTLens](https://github.com/git-disl/GPTLens)
- **核心アイデア**:
  ```
  従来の1段階検出 → 2段階の生成・識別フレームワーク
  
  ┌─────────────┐    ┌─────────────┐    ┌─────────────┐
  │   Auditor   │ →  │   Critic    │ →  │   Ranker    │
  │ (脆弱性候補)│    │ (妥当性評価)│    │(スコアリング)│
  └─────────────┘    └─────────────┘    └─────────────┘
  ```
  - **Auditor**: 高いランダム性で多くの候補を生成
  - **Critic**: 候補の妥当性を評価、偽陽性を削減
  - **Ranker**: 最終スコアリング
- **課題**: GPT-4の出力が時期によって変動する不安定性

#### 4. "iAudit: Fine-Tuning + LLM-based Agents" (2024)
- **著者**: Wei Ma, Daoyuan Wu, et al.
- **URL**: [arXiv:2403.16073](https://arxiv.org/abs/2403.16073)
- **掲載**: ICSE 2025
- **アプローチ**:
  1. **Detector** (ファインチューニング): 脆弱性の有無を判定
  2. **Reasoner** (ファインチューニング): 原因を生成
  3. **Ranker** (LLMエージェント): 最適な原因を選択
  4. **Critic** (LLMエージェント): 選択結果を議論・検証
- **結果**:
  - F1スコア: **91.21%**
  - 精度: **91.11%**
  - 原因の一致率: **38%**（Ground Truthと比較）

---

## 🔧 既存のAI監査ツール・プロジェクト

### オープンソースプロジェクト

| プロジェクト | Stars | アプローチ | 状態 |
|------------|-------|-----------|------|
| [GPTLens](https://github.com/git-disl/GPTLens) | 111 | Auditor-Critic 2段階 | 研究用 |
| [4naly3er](https://github.com/Picodes/4naly3er) | 550 | 静的解析 + レポート生成 | アクティブ |
| Slither (Codex検出器) | 6.1k | AI検出器統合 | 実験的 |

### 商用サービス

| サービス | 特徴 |
|---------|------|
| **Cyfrin Aderyn** | Rust製静的解析、AI機能開発中 |
| **OpenZeppelin Defender** | 監視・自動化、セキュリティ分析 |
| **Tenderly** | シミュレーション、デバッグ |

### ギャップ分析

```
┌────────────────────────────────────────────────────────────┐
│                      現状のギャップ                         │
├────────────────────────────────────────────────────────────┤
│ ❌ 完全自律型のAIバウンティハンターは存在しない            │
│ ❌ LLMとセキュリティツールを統合したエージェントがない      │
│ ❌ バウンティプログラムとの自動連携がない                   │
│ ❌ CTF/検証用の自動解答システムがない                      │
├────────────────────────────────────────────────────────────┤
│                      チャンス                               │
├────────────────────────────────────────────────────────────┤
│ ✅ GPTLens/iAuditのアイデアをエージェント化                │
│ ✅ Slither + LLM推論の統合                                 │
│ ✅ マルチエージェントによる議論・検証                      │
│ ✅ Foundryテスト自動生成によるPoC作成                      │
└────────────────────────────────────────────────────────────┘
```

---

## ��️ エージェントフレームワーク比較

### 詳細比較

| フレームワーク | Stars | 特徴 | 本プロジェクトへの適合性 |
|---------------|-------|------|------------------------|
| **LangGraph** | 23.2k | グラフベース、細かい制御、状態管理 | ⭐⭐⭐ 最適 |
| **CrewAI** | 42.6k | ロール定義、YAML設定、Flows | ⭐⭐ 良好 |
| **AutoGPT** | 181k | ビジュアルUI、汎用的 | ⭐ 過剰 |

### LangGraph

```python
# 特徴
- 状態管理が明示的
- グラフベースのワークフロー
- 細かい制御が可能
- Human-in-the-loop サポート
- Durable execution (障害耐性)

# コア概念
graph = StateGraph(State)
graph.add_node("analyze", analyze_code)
graph.add_node("verify", verify_finding)
graph.add_edge("analyze", "verify")
```

**推奨理由**:
- セキュリティ分析では **細かい制御** が重要
- 検出→検証→PoC作成の **明確なフロー** が必要
- **状態管理** が分析プロセスに適合

### CrewAI

```python
# 特徴
- ロールベースのエージェント定義
- LangChainから独立
- 5.76x高速（特定タスクで）
- Flows + Crews の組み合わせ

# コア概念
agent = Agent(
    role="Security Auditor",
    goal="Find vulnerabilities",
    backstory="Expert auditor..."
)
crew = Crew(agents=[agent], tasks=[task])
```

**メリット**:
- **直感的なロール定義** がセキュリティ監査に適合
- ドキュメントが豊富
- 学習曲線が緩やか

---

## 🧠 LLMの限界と対策

### 研究から判明した限界

| 限界 | 詳細 | 対策 |
|-----|------|------|
| **高い偽陽性率** | LLMは過剰に脆弱性を報告しがち | Criticエージェントで検証 |
| **出力の不安定性** | 同じ入力でも異なる結果 | Few-shotプロンプト、温度=0 |
| **コンテキスト制限** | 大きなコントラクトは処理困難 | チャンク分割、要約 |
| **精度のばらつき** | 脆弱性タイプで性能が異なる | 専門検出器との組み合わせ |
| **ハルシネーション** | 存在しない脆弱性を報告 | ツール（Slither等）で検証 |

### 推奨アーキテクチャ

```
┌─────────────────────────────────────────────────────────────┐
│                    Hybrid Architecture                       │
├─────────────────────────────────────────────────────────────┤
│                                                              │
│   ┌──────────────────┐    ┌──────────────────┐             │
│   │  Static Analysis │    │   LLM Reasoning  │             │
│   │    (Slither)     │    │   (Claude/GPT)   │             │
│   └────────┬─────────┘    └────────┬─────────┘             │
│            │                       │                        │
│            └───────────┬───────────┘                        │
│                        ▼                                     │
│            ┌──────────────────────┐                         │
│            │   Fusion & Ranking   │                         │
│            │   (LLM Agent)        │                         │
│            └───────────┬──────────┘                         │
│                        ▼                                     │
│            ┌──────────────────────┐                         │
│            │   Verification       │                         │
│            │   (Foundry PoC)      │                         │
│            └──────────────────────┘                         │
│                                                              │
└─────────────────────────────────────────────────────────────┘

利点:
- Slitherのパターン検出 + LLMの推論を融合
- 偽陽性をPoCで検証
- 信頼性の高い結果を生成
```

---

## 📈 LLM脆弱性検出の性能サマリ

### 研究結果の比較

| 研究 | モデル | 指標 | スコア |
|-----|-------|------|-------|
| 手動監査 (2023) | GPT-4 | 脆弱性タイプ正答率 | 40% |
| 手動監査 (2023) | GPT-4-32k | 真陽性率 (最良) | 78.7% |
| ChatGPT研究 (2024) | ChatGPT | Recall | 高 |
| ChatGPT研究 (2024) | ChatGPT | Precision | 低 |
| iAudit (2024) | Fine-tuned + Agents | F1 | 91.21% |
| iAudit (2024) | Fine-tuned + Agents | Accuracy | 91.11% |

### 重要な発見

1. **LLM単体は不十分** - 偽陽性が多すぎる
2. **2段階アプローチが有効** - 生成 + 検証
3. **ファインチューニングが効果的** - 汎用LLMより専用モデル
4. **マルチエージェントが有望** - 議論・検証で精度向上

---

## 🎯 本プロジェクトへの提言

### 推奨アーキテクチャ

```
┌─────────────────────────────────────────────────────────────┐
│              Eth Bounty Agent Architecture                   │
├─────────────────────────────────────────────────────────────┤
│                                                              │
│  Framework: LangGraph (状態管理、細かい制御)                 │
│  LLM: Claude 3.5 Sonnet (コード理解、推論)                   │
│                                                              │
│  ┌──────────┐   ┌──────────┐   ┌──────────┐   ┌──────────┐ │
│  │  Recon   │ → │  Audit   │ → │  Verify  │ → │  Report  │ │
│  │  Agent   │   │  Agent   │   │  Agent   │   │  Agent   │ │
│  └──────────┘   └──────────┘   └──────────┘   └──────────┘ │
│       │              │              │              │        │
│       ▼              ▼              ▼              ▼        │
│  ┌──────────┐   ┌──────────┐   ┌──────────┐   ┌──────────┐ │
│  │Etherscan │   │ Slither  │   │ Foundry  │   │ Markdown │ │
│  │  API     │   │ Analysis │   │  Test    │   │ Gen      │ │
│  └──────────┘   └──────────┘   └──────────┘   └──────────┘ │
│                                                              │
└─────────────────────────────────────────────────────────────┘
```

### GPTLens/iAuditからの学び

| アイデア | 本プロジェクトへの応用 |
|---------|---------------------|
| Auditor-Critic | 検出エージェント + 検証エージェント |
| Few-shot prompts | 脆弱性パターンの例示 |
| 温度パラメータ調整 | 生成時は高、検証時は低 |
| ランキングシステム | 信頼度スコアリング |
| Reasoner | 原因説明生成 |

### 差別化ポイント

1. **完全自律型** - 人間の介入なしにバウンティ発見
2. **ツール統合** - Slither/Foundry/Etherscanを統合
3. **PoC自動生成** - 発見した脆弱性のテストコード作成
4. **CTFクリア能力** - Ethernaut/DVDeFi自動解答

---

## 📚 参考文献

### 論文
1. David et al., "Do you still need a manual smart contract audit?", arXiv:2306.12338
2. Chen et al., "When ChatGPT Meets Smart Contract Vulnerability Detection", TOSEM 2025
3. Hu et al., "GPTLens: LLM-Powered Smart Contract Vulnerability Detection", TPS 2023
4. Ma et al., "iAudit: Fine-Tuning and LLM-based Agents", ICSE 2025

### ツール・フレームワーク
- [LangGraph](https://github.com/langchain-ai/langgraph) - 23.2k stars
- [CrewAI](https://github.com/crewAIInc/crewAI) - 42.6k stars
- [AutoGPT](https://github.com/Significant-Gravitas/AutoGPT) - 181k stars
- [Slither](https://github.com/crytic/slither) - 6.1k stars
- [GPTLens](https://github.com/git-disl/GPTLens) - 111 stars
- [4naly3er](https://github.com/Picodes/4naly3er) - 550 stars

---

## ✅ 調査結論

1. **LLM × スマートコントラクトセキュリティは研究段階**
   - 学術論文は増加中、しかし実用レベルはまだ
   
2. **2段階アプローチ（生成 + 検証）が有効**
   - GPTLens, iAuditで実証済み
   
3. **ハイブリッドアプローチが最も有望**
   - 静的解析ツール + LLM推論 + PoC検証
   
4. **本プロジェクトの優位性**
   - 完全自律型エージェントは未開拓
   - ツール統合 + マルチエージェントの組み合わせ
   - バグバウンティ特化は差別化ポイント

**結論: このプロジェクトは学術的にも実用的にも価値がある。先行研究の知見を活かしつつ、新しいアプローチ（自律型マルチエージェント）で差別化が可能。**

---

## 🆕 2025年12月 最新成果: Nyx Foundation 世界1位

### 概要

本調査時点（2026年1月）で、**AIエージェントによるスマートコントラクト脆弱性検出が実世界で成果を出した初の事例**が確認された。

**2025年12月24日、Nyx FoundationのAIエージェントがイーサリアム「Fusaka」監査コンテストで17件の脆弱性を発見し、報告件数で世界1位を獲得。**

### アーキテクチャの特徴

1. **2フェーズ構成**
   - Phase 1: 知識の構造化（仕様抽出 → 実装マッピング → チェックリスト作成）
   - Phase 2: 3戦略の並行実行

2. **3つの探索戦略**
   - 仕様ベース静的検査（17.6%）
   - **類似バグ探索（76.5%）** ← 最も効果的
   - 動的テスト生成（5.9%）

3. **既知バグパターンDB**
   - bugs_ethereum.json形式で過去の脆弱性を格納
   - CVE、CLの横展開検索

### 上記調査結論の更新

| 調査時点の結論 | 2025年12月以降の更新 |
|---------------|---------------------|
| 「LLM × セキュリティは研究段階」 | **実用レベルに到達（世界1位達成）** |
| 「実用レベルはまだ」 | **Fusaka監査で17件発見** |
| 「完全自律型は未開拓」 | **Nyx Foundationが先行** |

### 詳細

詳しくは [06-gohan-insights-research.md](./06-gohan-insights-research.md) を参照。
